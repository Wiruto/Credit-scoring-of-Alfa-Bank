<center> <img src = "img\logo.png" alt="drawing" style="width:400px;">

<center> <span style="background-size: 600px;background:White;color:RED;font-size: 60px;font-family: Comic Sans MS">Кредитный скоринг Альфа банка</span>

## Оглавление
1. [Описание проекта](#описание-проекта)
2. [Описание данных](#описание-данных)
3. [Принятые метрики](#принятые-метрики)
4. [Постановка задачи в рамках EDA](#постановка-задачи-в-рамках-eda)
5. [Постановка задачи в рамках Machine Learning](#постановка-задачи-в-рамках-machine-learning)
6. [Подготовка модели к продакшену](#Подготовка-модели-к-продакшену)
7. [Деплой модели](#Деплой-модели)
8. [Воспроизводимость модели](#Воспроизводимость-модели)
9. [Структура проекта](#структура-проекта)
10. [Установка проекта](#установка-проекта)
11. [Используемые зависимости](#используемые-зависимости)
12. [Авторы](#авторы)


## Описание проекта
Кредитный скоринг – важнейшая банковская задача. Стандартным подходом к ее решению   
является построение классических моделей машинного обучения, таких как логистическая   
регрессия и градиентный бустинг, на табличных данных, в том числе используя агрегации  
от каких-нибудь последовательных данных, например, транзакционных историй клиентов.   
Альтернативный подход заключается в использовании последовательных данных “как есть”,   
подавая их на вход рекуррентной нейронной сети.

В этом соревновании участникам предлагается решить задачу кредитного скоринга клиентов   
Альфа-Банка, используя только данные кредитных историй. [Источник](https://www.kaggle.com/competitions/alfa-bank-pd-credit-history)

## Описание данных

Датасет соревнования устроен таким образом, что кредиты для тренировочной выборки взяты   
за период в М месяцев, а кредиты для тестовой выборки взяты за последующие K месяцев.

Каждая запись кредитной истории содержит самую разнообразную информацию о прошлом кредите   
клиента, например, сумму, отношение клиента к кредиту, дату открытия и закрытия, информацию   
о просрочках по платежам и др. Все публикуемые данные тщательно анонимизированы.

Целевая переменная – бинарная величина, принимающая значения 0 и 1, где 1 соответствует   
дефолту клиента по кредиту.


## Принятые метрики

Метрика соревнования – $ROC$ $AUC$. Подробнее про метрику можно почитать, например, [здесь](https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/).

## Постановка задачи в рамках $EDA$

Данные о клиентах представлены в виде заявок, номера которых соотностятся с датами подачи заявки.  
Большему номеру соответствует более поздняя дата заявки.

Разделим процесс преобразования признаков на три части: 

1. Разделим признаки на под пространства.

2. Преобразуем кредитные операции клиента в его признаки, сохранив последовательность операций.  
Такие методы кодирования как $Ordinal$ $Encoding$, $OneHot$ $Encoding$ не подойдут, так как уничтожится   
информация о последовательности операций.

3. Преобразование признаков как дискренного ряда.  
Для каждого признака в "границах" одного "id" рассчитать статистические показатели ряда, такие как:  
   - среднее значение ряда (математическое ожидание);  
   - средне гармоническое значение ряда;   
   - стандартное отклонение;  
   - минимальное значение;  
   - 25% квантиль;  
   - 50% квантиль;  
   - 75% квантиль;  
   - максимальное значение;  
   - мода ряда (среднее значение мод);  
   - частота появления моды (средненего значения мод);
   - и т.д. 

## Постановка задачи в рамках $Machine$ $Learning$

1. Для решения задачи построем блендинг моделей. 

2. В качестве базовых и метамоделей рассмотрим следующие классические модели классификации:
    - $linearmodel.LogisticRegression$ (Логистическая регрессия);
    - $RandomForestClassifier$ (Деревья решений);
    - $HistGradientBoostingClassifier$ (Градиентный бустинг).

3. В результате, преобразования данных было получено два пространства признаков ($torow$ и $stat$ признаки),  
состоящих из 6 подпространств:
    - $date$ $features$;
    - $late$ $payments$ $features$; 
    - $credit$ $features$;
    - $relative$ $features$;
    - $payments$ $features$;
    - $service$ $features$.

4. На первом этапе построения потроения блендинга, сфокусируем обучение базовых моделей,   
на каждом подпространстве в отдельности друго от друга.  

5. На втором этапе построения блендинга, обучим несколько групп метамоделей.   
Первая группа метамоделей в качестве метапризнаков использует предсказания базовых моделей,    
обученных на пространстве признаков $torow$.  
Вторая группа метамоделей в качестве метапризнаков использует предсказания базовых моделей,    
обученных на пространстве признаков $stat$.

6. На третьем этапе построения блендинга метамодель обучится на метапризнаках пространства 
$torow$ и $stat$.

<center> <img src = "img\Blending.jpg" alt="drawing" style="width:1400px;">

## Подготовка модели к продакшену

Функционал результрующего блендинга "упакован" в файл [blending.py](blending.py).
Артефакты необходимые для работы блендинга blending.py находится в каталоге [models](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/tree/c3145cde389ff71dd62726f81c0aeff6f9ca6c5b/PROD%20server/models).
Для воспроизведения работы блендинга необходимо, чтобы каталог models и файл blending.py находились в одной директории.

## Деплой модели

С помощью фреймворка Flask блендинг был развернут на сервере [server.py](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/blob/c3145cde389ff71dd62726f81c0aeff6f9ca6c5b/PROD%20server/server.py), находящемся в директории [PROD server](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/tree/c3145cde389ff71dd62726f81c0aeff6f9ca6c5b/PROD%20server).
При запуске сервера пользователь попадает на стартовую страницу, в которой представлена инструкция для корректной работы сервера и форма для выбора файла с данными клиентов банка.

Инструкция включает в себя несколько правил:
- Сервер должен быть запущен из корневой директори файла server.py;
- Данные клиентов банка должны быть представлены в табличной форме, описанной в разделе
            <a href="https://www.kaggle.com/competitions/alfa-bank-pd-credit-history/data">Data</a>
  сорeвенования <a href="https://www.kaggle.com/competitions/alfa-bank-pd-credit-history">Kaggle</a> от Альфа Банка;
- Таблица с данными клиентов банка должна быть сохранена в формате csv.</li>

Dataset c данными клиентов банка можно скачать в разделе <a href="https://www.kaggle.com/competitions/alfa-bank-pd-credit-history/data">Data</a> 
соревнования на платформе Kaggle или на GitHub репозитории автора блендинга: <a href="https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/blob/372722316dc7f0346da4bbed9568b385d74fbfe1/data/client_data.csv">Wiruto</a>(сокращенный DataSet на 24 id клиента).

Для выполения кредитного скоринга клиентов банка необходимо сохранить Dataset данными клинетов в любой директории компьютера и выберите его с помощью формы представленной на сервере.

## Воспроизводимость модели


Для обеспечения воспроизводимости сервера на разных устройствах, был собран Docker Image.

Скачать образ сервера c Docker Hub можно командой:
```
docker pull kolobovviktor/blending_alpha_bank
```

Команда для корректного запуска сервера:
```
docker run -it --rm --name=server_container -p=8000:8000 blending_alpha_bank
```





## Выводы

<span style="color:Blue">

Качество полученной модели блендинга по метрике $ROC$ $AUC$:
- на тренировочном наборе: $ROC$ $AUC = 0.757$;
- на валидационном наборе: $ROC$ $AUC = 0.765$;
- на отложенном наборе: $ROC$ $AUC = 0.756$;
- на соревновательном ($kaggle$) наборе: $ROC$ $AUC = 0.743$;

<center> <img src = "img\kaggle.png" alt="drawing" style="width:1400px;">

**Мероприятия по возможному улучшению качества модели:**

1. Проанализировать данные на наличие выбросов и нерепрезентотивных данных. Скорее всего   
есть клиенты, данные которых "вводят в заблуждение" модель.  

2. Проанализировать влияние выбранных статистических характеристик, формирующих $dataset$ $stat$.  
Возможно, использование некоторых характеристики наоборот ухудшает качество модели.   
Возможно, есть иные характеристики числовых рядов которые были не учтены.  

3. Проанализирровать влияние размера обучающего набора на каждом этапе на качество результирующей модели.   
Возможно имеет смысл большую часть данных "потратить" на обучение базовых моделей, возможно наоборот.  

4. Проанализировать влияние подпространств признаков на результаты $first$ $metamodels$.  
Некоторые подпространства показали низкое качество на базовых моделеях, Возможно имеет смысл    
не использовать все подпространства признаков или разделить пространство признаков не на 6 выбранных     
подпространств, а с помощью методов класстеризации.   

5. Изучить вопрос выбранных базовых моделей. Возможно, имеет смысл сменить их или использовать не все.  
В проссе обучения на первом этапе, модель логистической регресии показала наихудшие результаты.

6. Проанализировать подбор гиперпараметров каждой модели. Сменить диапозоны параметров,  
выбрать дополнительные гиперпермараметры и т.д.

7. Сменить критерии "лучших" моделей. Возможно, имеет смысл использовать только один критерий для  
определения "лучших" моделей. В построенном блендинге на каждом этапе использовались все "лучшие"   
модели с предыдущего этапа. Возможно, есть смысл показывать метамодели результаты не от всех "лучших" моделей.

8. Увеличить или уменьшить глубину блендинга.  

9. Использовать не блендинг, а стекинг моделей.  

10. Использовать не блендинг, а нейронную сеть.  

</span>

## Структура проекта
* [PROD server](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/tree/c3145cde389ff71dd62726f81c0aeff6f9ca6c5b/PROD%20server) - каталог с установкой сервера server.py;
* [data](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/tree/c3145cde389ff71dd62726f81c0aeff6f9ca6c5b/data) - каталог с данными клиентов банка (сокращенный DataSet на 24 id клиента);
* [img](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/tree/c3145cde389ff71dd62726f81c0aeff6f9ca6c5b/img) - каталог с используемыми изображениями;
* [part_1_EDA.ipynb](part_1_EDA.ipynb) - jupyter-ноутбук, содержащий код проекта разведовательного анализа данных;
* [part_2_ML1.ipynb](part_2_ML1.ipynb) - jupyter-ноутбук, содержащий код проекта машинного обучения базовых моделей блендинга;
* [part_3_ML2.ipynb](part_3_ML2.ipynb) - jupyter-ноутбук, содержащий код проекта машинного обучения метамоделей "первого слоя";
* [part_4_ML3.ipynb](part_4_ML3.ipynb) - jupyter-ноутбук, содержащий код проекта машинного обучения метамоделей "второго слоя" и результирующей метамодели;
* [part_5_PROD.ipynb](part_5_PROD.ipynb) - jupyter-ноутбук, содержащий код проекта подготовки модели к продакшену и проверки модели на соревновательном Dataset Kaggle;
* README.md - краткое описание проекта;
* optuna_studies.db - результаты оптимизации моделей;
* requirements.txt - файл используемых библиотек и зависимостей.

## Используемые зависимости

Используемые библиотеки и зависимости представлены в файле: [requirements.txt](https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank/blob/master/requirements.txt)

## Установка проекта
Проект:
```
git clone https://github.com/Wiruto/Credit-scoring-of-Alfa-Bank
```

Образ сервера на Docker Hub:
```
docker pull kolobovviktor/blending_alpha_bank
```

Запуск сервера:
```
docker run -it --rm --name=server_container -p=8000:8000 blending_alpha_bank
```
## Авторы

* [Колобов Виктор Валерьевич](https://github.com/Wiruto)


